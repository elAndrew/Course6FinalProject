---
title: "Central Limit Theorem and Inferential Data Analysis"
author: "Andrew Witherspoon"
output:
  html_document: default
  pdf_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##Part 1: Central Limit Theorem Simulation

The Central Limit Theorem is an important theorem in statistics, which states, that a distribution of means of independent independently distributed random variables, will take on the shape of a normal distribution if our sample size big enough.  This is extremely useful, as so many of our statistical tools rely on the assumption of normality.

Let's start by looking at an exponential distribution, which is decidedly not a normal shape.  Here is a look at the shape of exponential distribution, with a rate (lambda) of 0.2:
```{r, fig.align='center', fig.height = 2, echo=FALSE}
x <- seq(0, 50, length.out=1000)
par(mar=c(2, 2, .75, .1))
plot(x, dexp(x, rate=0.2), type ="l")
```

If The Central Limit Theorem is correct, then if we take a random sample from the above distribution, take the mean of that random sample, subtract off the population mean (which is 1/lambda), divide by the standard error of the estimate, and do this n times, the distribution of *these* sample means will be approximately normal for large values of n.

To put the above paragraph into a formula notation,
$$\frac{\bar X_n - \mu}{\sigma / \sqrt{n}} = 
    \frac{\mbox{Estimate} - \mbox{Mean of the Estimate}}{\mbox{Standard Error of the Estimate}}
$$

Let's run a simulation to see if this is correct.  We will take a 1000 samples of 40 random numbers from the above exponential distribution:
```{r}
lambda = .2 #this is the rate from the above distibution
n = 40 #sample size
nSamps = 1000 #the number of samples

samps <- matrix(, nrow = nSamps, ncol = n)
for(i in 1:nSamps){
       samps[i,] <- rexp(n, rate = lambda) 
}

```

Now we can take the mean of each of our 1000 samples to get the sample mean:
```{r}
sampleMeans <- apply(samps, 1, mean)
```
Now let's take the CLT formula piece by piece.  Subtract the population mean (1/lambda) from the sample mean:
$$\bar X_n - \mu
$$
```{r}
CLTtop <- (sampleMeans - 1/lambda)
```
Next divide the sample standard deviation (also 1/lambda) by the square root of the sample size, n (this is the standard error of the mean):
$$\sigma/ \sqrt{n}
$$
```{r}
CLTbottom <- (1/lambda)/sqrt(n)
```
Now divide former by the latter:
$$\frac{\bar X_n - \mu}{\sigma / \sqrt{n}}
$$
```{r}
CLT <- CLTtop / CLTbottom
```
And finally we will plot *that* distribution as a histogram:
```{r, fig.align='center', fig.height=2, echo=FALSE}
par(mar=c(2, 2, .75, .1))
hist(CLT, freq = FALSE, xlim= c(-3,3), ylim = c(0,.5))
lines(seq(-3, 3, length = 100), dnorm(seq(-3, 3, length = 100)), col = grey(.8), lwd = 3)
```
We've overlayed a normal distribution density plot to show that our histogram is a very close fit to a standard normal.  The Central Limit Theorem works!

To further illustrate, the mean of a standard normal is 0, and the variance is 1.  Let's compare that to the mean and variance of our CLT calculation from our simulation samples:
```{r}
mean(CLT)
var(CLT)
```
Looks like we're pretty close!  With even larger values of n, these would be get even closer.

##Part 2: Inferential Data Analysis
```{r, echo=FALSE}
library(datasets)
#ToothGrowth is now available as a dataframe
```
For this exercise, we will use the **ToothGrowth** data, which is in the R datasets package.The R documentation gives a description of the data:

*"The response is the length of odontoblasts (cells responsible for tooth growth) in 60 guinea pigs. Each animal received one of three dose levels of vitamin C (0.5, 1, and 2 mg/day) by one of two delivery methods, orange juice or ascorbic acid (a form of vitamin C and coded as VC)."*

```{r, echo=FALSE}
library(knitr)
kable(table(ToothGrowth[,2:3]), align = "l")
```

As the table above shows, there are 10 observations for each combination of dose, and supplement type.

Let's start by comparing the mean tooth length of guinea pigs treated with orange juice to the tooth length of those treated with ascorbic acid:
```{r, fig.align='center', fig.height=2, echo=FALSE}
par(mar=c(2, 2, .75, .1))
boxplot(len ~ supp, data = ToothGrowth)
```
Our null hypothesis is that the mean tooth length of the OJ group not different than the mean tooth length of the VC group.  We'll run a t-test to see if we can reject this hypothesis:
```{r}
OJ <-  ToothGrowth$len[ToothGrowth$supp=="OJ"]
VC <-  ToothGrowth$len[ToothGrowth$supp=="VC"]
t.test(OJ, VC, alternative = "two.sided", conf.level = .95)$conf.int
```

The 95% confidence interval contains the value 0, therefore we cannot reject the null hypothesis.  The data does not show that tooth length is affected by supplement type.

Let's do the same type of hypothesis testing based on dose:
```{r, fig.align='center', fig.height=2, echo=FALSE}
par(mar=c(2, 2, .75, .1))
boxplot(len ~ dose, data = ToothGrowth)
dose0.5 <-  ToothGrowth$len[ToothGrowth$dose==0.5]
dose1 <-  ToothGrowth$len[ToothGrowth$dose==1]
dose2 <-  ToothGrowth$len[ToothGrowth$dose==2]
```
A dose of 0.5 and a dose of 2 have the largest mean difference, so let's use these values for our hypothesis testing.  Once again, our null hypothesis will be that the mean of dose0.5 and the mean of dose2 are not different.
```{r}
t.test(dose0.5, dose2, alternative = "two.sided", conf.level = .95)$conf.int
```
We can reject the null hypothesis, as the confidence interval does not contain 0.  With 95% confidence, the data shows that the dose does have an effect on tooth length.


**Full markdown document code available at:** <https://github.com/elAndrew/Course6FinalProject/blob/master/Project.Rmd>